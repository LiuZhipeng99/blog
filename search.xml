<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hello_Hexo</title>
    <url>/blog/2020/05/05/Hello-Hexo/</url>
    <content><![CDATA[<p>本篇主要介绍如何用Hexo搭建Github Pages，并且对比了同类静态博客框架，记录了部署方面的易错认知，提出了一些常用插件及美化博客的思路。PS：本文非小白教程类</p>
<a id="more"></a>

<h2 id="Hexo-GitHub-Pages"><a href="#Hexo-GitHub-Pages" class="headerlink" title="Hexo+GitHub Pages"></a>Hexo+GitHub Pages</h2><p>第一次使用GitHubpages发布博客，之前是wordpress的动态博客，但由于博客性质适合静态网页，于是跳到两年前埋下伏笔处Githubpages。既不用续域名做备案，也不用租用服务器（虽然牛客网那白嫖了一年华为云的）。</p>
<h4 id="jekyll-or-hexo"><a href="#jekyll-or-hexo" class="headerlink" title="jekyll or hexo"></a>jekyll or hexo</h4><p>​    目前两大静态博客框架：<a href="jekyllcn.com">Jekyll</a>和<a href="heox.io">hexo</a>。</p>
<ul>
<li>前者本身是被GitHub采用渲染的，而后者是先生成静态文件再上传，由此分离开来。</li>
<li>另一个大区别是依赖，前者需要本地安装ruby等而后者需要nodejs，他们的环境配置都有相应文档，另外hexo中文文档对我这种低水平英语很贴心</li>
</ul>
<h4 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h4><ul>
<li>经过探索参考博客，纠正了自己几个错误认知：<ol>
<li>hexo初始化后文件夹位置自由，所以如果把他放到一个repo就能通过clone来多端写文（我是放在user-page的repo），这样既能管理blog也能做其他静态web项目（如HX）。</li>
<li>我之前有个错误认知是只能访问user-page（也就是username.github.io），其实每个repo都能设置page（如username.github.io/blog，它是blog库的一个分支），它需要的是一个分支。而userpage只能是master分支。。</li>
<li>需要deploy时需npm下载git的包，站点配置文件的deploy项改为对应的repo和对应分支（国内gitee同样）。</li>
</ol>
</li>
<li>本站使用的Next主题。先据hexo文档配置好hexo环境，再下载主题到配置文件theme中，通过git clone <em>repo_url</em>  theme/next 一步完成也可下载压缩包解压到theme目录下。修改站点配置文件的theme字段即可。需要查看next的文档来配置，继而有下面的特效美化 </li>
</ul>
<h2 id="博客美化（待续）"><a href="#博客美化（待续）" class="headerlink" title="博客美化（待续）"></a>博客美化（待续）</h2><blockquote>
<p>下面在next配置文件有接口不用多写代码，看其文档使用方法再进主题配置文件修改，下面主要针对其他类</p>
</blockquote>
<h4 id="评论系统"><a href="#评论系统" class="headerlink" title="评论系统"></a>评论系统</h4><ul>
<li>此外有韩国<a href="livere.com">来必力</a>。在next主题中使用参见<a href="http://theme-next.iissnan.com/third-party-services.html" target="_blank" rel="noopener">文档</a>第三方服务来配置。</li>
<li>基于github-issue的<a href="https://imsun.net/posts/gitment-introduction/" target="_blank" rel="noopener">gitment</a></li>
<li>另找到个valine有使用<a href="https://valine.js.org" target="_blank" rel="noopener">文档</a> 注册用的leancloud可以再创建个app给下面阅读量用<ul>
<li>在2020.4.22的更新中：修复使用了低版本的<code>av-min.js</code>造成的初始化错误，这也是当前next主题还未修改的。只需要将_src=”//cdn1.lncld.net/static/js/3.0.4/av-min.js引入的这个leancloud操作库注释，否则会出现AV对象没有初始化的报错</li>
</ul>
</li>
<li>PS：摘要使用<!--more-->分割；阅读全文修改主题配置auto_excerpt字段</li>
</ul>
<h4 id="恶搞标题"><a href="#恶搞标题" class="headerlink" title="恶搞标题"></a>恶搞标题</h4><ul>
<li><p>点击<a href="diygod.me">效果</a></p>
</li>
<li><p>在主题文件下找到head文件里加入</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> OriginTitle = <span class="built_in">document</span>.title;</span><br><span class="line"><span class="keyword">var</span> titleTime;</span><br><span class="line"><span class="built_in">document</span>.addEventListener(<span class="string">'visibilitychange'</span>, <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">document</span>.hidden) &#123;</span><br><span class="line">        $(<span class="string">'[rel="icon"]'</span>).attr(<span class="string">'href'</span>, <span class="string">"/img/trhx2.png"</span>);</span><br><span class="line">        <span class="built_in">document</span>.title = <span class="string">'ヽ(●-`Д´-)ノ人呢！'</span>;</span><br><span class="line">        clearTimeout(titleTime);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        $(<span class="string">'[rel="icon"]'</span>).attr(<span class="string">'href'</span>, <span class="string">"/img/trhx2.png"</span>);</span><br><span class="line">        <span class="built_in">document</span>.title = <span class="string">'ヾ(Ő∀Ő3)ノ回来了！'</span> + OriginTitle;</span><br><span class="line">        titleTime = setTimeout(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">            <span class="built_in">document</span>.title = OriginTitle;</span><br><span class="line">        &#125;, <span class="number">2000</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>



</li>
</ul>
<h4 id="看板娘"><a href="#看板娘" class="headerlink" title="看板娘"></a>看板娘</h4><ul>
<li><a href="https://www.cnblogs.com/ButterflyEffect/p/10839613.html" target="_blank" rel="noopener">live2d</a></li>
</ul>
<h4 id="点击滑动特效"><a href="#点击滑动特效" class="headerlink" title="点击滑动特效"></a>点击滑动特效</h4><ul>
<li><p>点击🎈爆炸:放在主题文件下_layout文件中</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 点击出现彩色气球爆炸效果 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">canvas</span> <span class="attr">class</span>=<span class="string">"fireworks"</span> <span class="attr">style</span>=<span class="string">"position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;"</span> &gt;</span><span class="tag">&lt;/<span class="name">canvas</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span> <span class="attr">src</span>=<span class="string">"//cdn.bootcss.com/animejs/2.2.0/anime.min.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"https://cdn.jsdelivr.net/gh/wallleap/cdn/js/clickBom.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>



</li>
</ul>
<ul>
<li><p>光标 点击烟花效果<a href="https://www.cnblogs.com/axqa/p/11537599.html" target="_blank" rel="noopener">这里</a></p>
</li>
<li><p>鼠标滑过特效 星星残影：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"https://cdn.jsdelivr.net/gh/wallleap/cdn/js/xuehua.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>



</li>
</ul>
<h4 id="网站运行时"><a href="#网站运行时" class="headerlink" title="网站运行时"></a>网站运行时</h4><ul>
<li><p>在主题footer加入：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">id</span>=<span class="string">"timeDate"</span>&gt;</span>载入天数...<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">id</span>=<span class="string">"times"</span>&gt;</span>载入时分秒...<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="javascript">  <span class="keyword">var</span> now = <span class="keyword">new</span> <span class="built_in">Date</span>(); </span></span><br><span class="line"><span class="actionscript">  <span class="function"><span class="keyword">function</span> <span class="title">createtime</span><span class="params">()</span> </span>&#123; </span></span><br><span class="line"><span class="javascript">    <span class="keyword">var</span> grt= <span class="keyword">new</span> <span class="built_in">Date</span>(<span class="string">"03/08/2020 16:44:00"</span>);<span class="comment">//此处修改你的建站时间或者网站上线时间 </span></span></span><br><span class="line">    now.setTime(now.getTime()+250); </span><br><span class="line"><span class="javascript">    days = (now - grt ) / <span class="number">1000</span> / <span class="number">60</span> / <span class="number">60</span> / <span class="number">24</span>; dnum = <span class="built_in">Math</span>.floor(days); </span></span><br><span class="line"><span class="javascript">    hours = (now - grt ) / <span class="number">1000</span> / <span class="number">60</span> / <span class="number">60</span> - (<span class="number">24</span> * dnum); hnum = <span class="built_in">Math</span>.floor(hours); </span></span><br><span class="line"><span class="javascript">    <span class="keyword">if</span>(<span class="built_in">String</span>(hnum).length ==<span class="number">1</span> )&#123;hnum = <span class="string">"0"</span> + hnum;&#125; minutes = (now - grt ) / <span class="number">1000</span> /<span class="number">60</span> - (<span class="number">24</span> * <span class="number">60</span> * dnum) - (<span class="number">60</span> * hnum); </span></span><br><span class="line"><span class="javascript">    mnum = <span class="built_in">Math</span>.floor(minutes); <span class="keyword">if</span>(<span class="built_in">String</span>(mnum).length ==<span class="number">1</span> )&#123;mnum = <span class="string">"0"</span> + mnum;&#125; </span></span><br><span class="line">    seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); </span><br><span class="line"><span class="javascript">    snum = <span class="built_in">Math</span>.round(seconds); <span class="keyword">if</span>(<span class="built_in">String</span>(snum).length ==<span class="number">1</span> )&#123;snum = <span class="string">"0"</span> + snum;&#125; </span></span><br><span class="line"><span class="javascript">    <span class="built_in">document</span>.getElementById(<span class="string">"timeDate"</span>).innerHTML = <span class="string">"本站已安全运行 "</span>+dnum+<span class="string">" 天 "</span>; </span></span><br><span class="line"><span class="javascript">    <span class="built_in">document</span>.getElementById(<span class="string">"times"</span>).innerHTML = hnum + <span class="string">" 小时 "</span> + mnum + <span class="string">" 分 "</span> + snum + <span class="string">" 秒"</span>; </span></span><br><span class="line">  &#125; </span><br><span class="line"><span class="actionscript">  setInterval(<span class="string">"createtime()"</span>,<span class="number">250</span>);</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="背景显示飘动的彩带"><a href="#背景显示飘动的彩带" class="headerlink" title="背景显示飘动的彩带"></a>背景显示飘动的彩带</h4><ul>
<li><p>同上layout：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"https://cdn.jsdelivr.net/gh/wallleap/cdn/js/piao.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>背景显示分子状线条</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"https://cdn.jsdelivr.net/gh/wallleap/cdn/js/canvas-nest.min.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="樱花飘落或雪花飘落"><a href="#樱花飘落或雪花飘落" class="headerlink" title="樱花飘落或雪花飘落"></a>樱花飘落或雪花飘落</h4><ul>
<li>樱花src：_<a href="https://cdn.jsdelivr.net/gh/wallleap/cdn/js/sakura.js_同上位置" target="_blank" rel="noopener">https://cdn.jsdelivr.net/gh/wallleap/cdn/js/sakura.js_同上位置</a></li>
<li>雪花src: _<a href="https://cdn.jsdelivr.net/gh/wallleap/cdn/js/xuehuapiaoluo.js_或者_https://cdn.jsdelivr.net/gh/wallleap/cdn/js/snow.js_选择一个" target="_blank" rel="noopener">https://cdn.jsdelivr.net/gh/wallleap/cdn/js/xuehuapiaoluo.js_或者_https://cdn.jsdelivr.net/gh/wallleap/cdn/js/snow.js_选择一个</a></li>
</ul>
<h4 id="禁用按键"><a href="#禁用按键" class="headerlink" title="禁用按键"></a>禁用按键</h4><ul>
<li><p>禁用了右键F12等</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"https://cdn.jsdelivr.net/gh/wallleap/cdn/js/noSomeKey.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="wordcout"><a href="#wordcout" class="headerlink" title="wordcout"></a>wordcout</h4><ul>
<li><p>在主题有字段post_wordcout：需要先npm下载hexo-wordcout才能用</p>
</li>
<li><p>另外默认没有单位，修改themes\next\layout_macro\post.swig：例如</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">title</span>=<span class="string">"&#123;&#123; __('post.min2read') &#125;&#125;"</span>&gt;</span></span><br><span class="line">   &#123;&#123; min2read(post.content) &#125;&#125; 分钟</span><br><span class="line"> <span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br></pre></td></tr></table></figure>



</li>
</ul>
<h4 id="更多特效"><a href="#更多特效" class="headerlink" title="更多特效"></a>更多特效</h4><ul>
<li><a href="https://blog.csdn.net/u011475210/article/details/79023429#comments" target="_blank" rel="noopener">播放器头像旋转等</a>、<a href="https://blog.csdn.net/weixin_43738731/article/details/85843474" target="_blank" rel="noopener">next深度定制</a>、添加文章阅读量统计功能（next文档第三方服务部分：记得手动加Counter类）、数据统计与分析</li>
</ul>
<h4 id="解决时延问题"><a href="#解决时延问题" class="headerlink" title="解决时延问题"></a>解决时延问题</h4><p><img src="data:image/png;base64,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" data-original="https://kivid.github.io/blog/image/%E8%A7%A3%E5%86%B3%E6%97%B6%E5%BB%B6.png" alt="需要根据public结构"></p>
<ul>
<li>发布后发现加载过慢于是看看是什么原因。第一个是font即谷歌字体的镜像网站无法访问，本来查了些镜像站发现不会用，而原本默认的居然能访问于是在主题配置文件中更改font字段下的host。</li>
<li>第二个是disq第三方评论网站被墙，只需将其字段设false。</li>
<li>还有个是head的背景图片url失效去主题博主网站<a href="https://notes.doublemine.me/images/header-background.jpg" target="_blank" rel="noopener">下载了</a>（不知道为什么能Get到可能是本地的）。但本地应用由于hexo生成public文件夹发布会找不到于是使用其url（在head-style文件）</li>
<li>Aplayer是js没有找到，查看博客的repo文件。</li>
<li>网易云外链在博客只能点击几首歌，在这里发现是外链问题。依次对单曲产生外链发现是版权问题。</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li><p>搭建hexo博客已经是一搜一大片。如果是第一次做先弄清楚前端相关知识，再从hexo理解和文档入手。配置好环境条件：能生成一个本地能访问的前端。再者就是配置基础项可见文档，如何发布文档和上面已经说明。只是发文到此可止。</p>
</li>
<li><p>美化博客就像DIY（像我们这种后端）简直就是东拼西凑。第一步是换个生态好的，稳定维护的主题，我用的是魔改的Next。文档之全面让我们与代码分离开来。下面就是本博客的主要得分。</p>
</li>
</ul>
<ol>
<li><p>先是博客插件。第一个就是给静态博客添加评论系统，参考文档发现next加入了诸多第三方评论系统。例如valine、gitment、来必力等。使用方法都很简单，注册拿到appid和appkey 插入到主题配置文件的相应字段。</p>
</li>
<li><p>还有就是文章字数显示浏览次数用的wordcount和leancloud都在文档有接口</p>
</li>
<li><p>另外就是参考diygod博客的小交互，例如点击烟花，吸底apalyer，背景点击变化</p>
</li>
<li><p>还有些tips：摘要分割（需改主题配置），博客边界阴影，看板娘，评论区加入每日一词和正则检验，文章加密，side：头像转动，划入显示链接。</p>
<p>PS：点击菜单链接中有%20应该是空格字符转义，删除||前面空格可用。菜单中除了about和404需要写其他都能生成。</p>
</li>
<li><p>现在还有个点是valine admin没有部署（评论邮件通知），因为leancloud没配置好，可能要另外域名来绑定才行.</p>
</li>
</ol>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>Githubpages</tag>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/blog/2020/05/05/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>给文章加密</title>
    <url>/blog/2020/05/07/%E7%BB%99%E6%96%87%E7%AB%A0%E5%8A%A0%E5%AF%86/</url>
    <content><![CDATA[<p>Next主题没有发现内置加密，试试脚本加密</p>
<a id="more"></a>
<h4 id="实现方法"><a href="#实现方法" class="headerlink" title="实现方法"></a>实现方法</h4><ul>
<li>在主题文件下layout/_partials/head.swig插入如下代码<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="actionscript">    (<span class="function"><span class="keyword">function</span><span class="params">()</span></span>&#123;</span></span><br><span class="line"><span class="actionscript">        <span class="keyword">if</span>(<span class="string">'&#123;&#123; page.password &#125;&#125;'</span>)&#123;</span></span><br><span class="line"><span class="actionscript">            <span class="keyword">if</span> (prompt(<span class="string">'请输入文章密码'</span>) !== <span class="string">'&#123;&#123; page.password &#125;&#125;'</span>)&#123;</span></span><br><span class="line"><span class="actionscript">                alert(<span class="string">'密码错误！'</span>);</span></span><br><span class="line">                history.back();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;)();</span><br><span class="line"><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>然后写文章加个password字段类似<br>titile: your title<br>password: your password</li>
</ul>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title>Tensorflow学习笔记(一）</title>
    <url>/blog/2020/05/08/tensorflow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<pre><code>本文回忆学习tensorflow的经验和总结
&lt;!--more--&gt;</code></pre><blockquote>
<p>想学习tf的人，或许啃完了网上的机器学习课程（吴恩达），或许正在上学校里的机器学习课程，抑或是只解皮毛而想快速入门。<br>学前建议：<br> 1.对于没有任何基础的兄台还是老老实实的回去看看高数，不然走不下去。<br> 2.对于正在学机器学习的人来说，你或许已经了解梯度下降，知道若干种损失函数激活函数，但建议先自己动手做网络构建走基础路线。例如吴恩达课程和本人<a href="https://github.com/microsoft/ai-edu/tree/master/A-%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B" target="_blank" rel="noopener">用的</a>（基于python）。<br> 3.对于基础扎实的同学来说，tf将会是你大有作为的舞台。尽管去看那些网上丰富的文档相信你不会迷路。</p>
</blockquote>
<h4 id="关于搭建环境"><a href="#关于搭建环境" class="headerlink" title="关于搭建环境"></a>关于搭建环境</h4><p>  如果是初学TF建议使用cpu版本，这样省去诸多麻烦。例如gpu版本需要电脑gpu支持（nividia，需要驱动），并且安装cuDnn和cudatoolkit（需要和tensorflow版本对应），另外python高版本还未适配tensorflow所以不能安装过高版本，此时anaconda闪亮登场，它不仅能虚拟环境让py、包等与系统隔离开，指定python版本和自动下相应cuda搭配。当然如果用cpu版本无需考虑。</p>
  <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">print(tf.__version__) <span class="comment">#打印即成功</span></span><br></pre></td></tr></table></figure>

<h4 id="关于keras和tf-keras"><a href="#关于keras和tf-keras" class="headerlink" title="关于keras和tf.keras"></a>关于keras和tf.keras</h4><p>  现在都是直接下载tensorflow里面内置了keras，官方也推荐使用后者，相当于后者是将其收纳了，实际上关系是：tensorflow作为其计算工具，后者是tensorflow的高级api，简单来说就是协作关系，keras是只笔，tensorflow是张纸。</p>
<h4 id="初识Tensorflow"><a href="#初识Tensorflow" class="headerlink" title="初识Tensorflow"></a>初识Tensorflow</h4><blockquote>
<p>前馈神经网络：<strong>分为多层, 相邻层之间全连接, 不存在同层连接与跨层连接</strong>. 整个网络中无反馈，可用一个有向无环图表示.用标准bp算法训练（基于SDG）。</p>
<p>以下从特性到建立模型和训练。从代码实战开始</p>
</blockquote>
<ol>
<li>了解其特效和基础–自动求导机制</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = tf.Variable(initial_value=<span class="number">3.</span>)</span><br><span class="line"><span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">  y = <span class="number">3</span>*tf.square(x)</span><br><span class="line">  z = y+<span class="number">3</span>*x</span><br><span class="line">z_grad = tape.gradient(z,x)</span><br><span class="line">print(y,z,z_grad)</span><br><span class="line"><span class="comment">#利用其求偏导</span></span><br><span class="line">X = tf.constant([[<span class="number">1.</span>, <span class="number">2.</span>], [<span class="number">3.</span>, <span class="number">4.</span>]])</span><br><span class="line">y = tf.constant([[<span class="number">1.</span>], [<span class="number">2.</span>]])</span><br><span class="line">w = tf.Variable(initial_value=[[<span class="number">1.</span>], [<span class="number">2.</span>]])</span><br><span class="line">b = tf.Variable(initial_value=<span class="number">1.</span>)</span><br><span class="line"><span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">    L = tf.reduce_sum(tf.square(tf.matmul(X, w) + b - y))</span><br><span class="line">w_grad, b_grad = tape.gradient(L, [w, b])        <span class="comment"># 计算L(w, b)关于w, b的偏导数</span></span><br><span class="line">print(L, w_grad, b_grad)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 线性回归示例：生成data</span></span><br><span class="line">X_raw = np.array([<span class="number">2013</span>, <span class="number">2014</span>, <span class="number">2015</span>, <span class="number">2016</span>, <span class="number">2017</span>], dtype=np.float32)</span><br><span class="line">y_raw = np.array([<span class="number">12000</span>, <span class="number">14000</span>, <span class="number">15000</span>, <span class="number">16500</span>, <span class="number">17500</span>], dtype=np.float32)</span><br><span class="line"></span><br><span class="line">X = (X_raw - X_raw.min()) / (X_raw.max() - X_raw.min())</span><br><span class="line">y = (y_raw - y_raw.min()) / (y_raw.max() - y_raw.min())</span><br><span class="line">X = tf.constant(X)</span><br><span class="line">y = tf.constant(y)</span><br><span class="line"></span><br><span class="line">a = tf.Variable(initial_value=<span class="number">0.</span>)</span><br><span class="line">b = tf.Variable(initial_value=<span class="number">0.</span>)</span><br><span class="line">variables=[a,b]</span><br><span class="line">num_epoch = <span class="number">10000</span></span><br><span class="line">opt = tf.keras.optimizers.SGD(learning_rate=<span class="number">5e-4</span>)</span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> range(num_epoch):</span><br><span class="line">  <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">      y_pred = a * X + b</span><br><span class="line">      loss = tf.reduce_sum(tf.square(y_pred-y))</span><br><span class="line">  grads = tape.gradient(loss,variables)</span><br><span class="line">  opt.apply_gradients(grads_and_vars=zip(grads,variables))</span><br><span class="line">print(a,b)</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>创建自己的模型作用如上面的运算和variable（下面的方法都是各类框架通用，没有使用高级api，都是自定义网络）</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModel</span><span class="params">(tf.keras.Model)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().__init__()     <span class="comment"># Python 2 下使用 super(MyModel, self).__init__()</span></span><br><span class="line">        <span class="comment"># 此处添加初始化代码（包含 call 方法中会用到的层），例如</span></span><br><span class="line">        <span class="comment"># layer1 = tf.keras.layers.BuiltInLayer(...)</span></span><br><span class="line">        <span class="comment"># layer2 = MyCustomLayer(...)</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, input)</span>:</span></span><br><span class="line">        <span class="comment"># 此处添加模型调用的代码（处理输入并返回输出），例如</span></span><br><span class="line">        <span class="comment"># x = layer1(input)</span></span><br><span class="line">        <span class="comment"># output = layer2(x)</span></span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 还可以添加自定义的方法</span></span><br><span class="line"><span class="comment">#由于继承自model其有variable这一属性获取所有变量</span></span><br><span class="line"><span class="comment">#将上例的y=ax+b模型化</span></span><br><span class="line">X = tf.constant([[<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>], [<span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">6.0</span>]])</span><br><span class="line">y = tf.constant([[<span class="number">10.0</span>], [<span class="number">20.0</span>]])</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Linear</span><span class="params">(tf.keras.Model)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.dense = tf.keras.layers.Dense(</span><br><span class="line">            units = <span class="number">1</span>,</span><br><span class="line">            activation=<span class="literal">None</span>,</span><br><span class="line">            kernel_initializer=tf.zeros_initializer(),</span><br><span class="line">            bias_initializer=tf.zeros_initializer()</span><br><span class="line"></span><br><span class="line">            )</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self,input)</span>:</span></span><br><span class="line">        output = self.dense(input)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">model = Linear()</span><br><span class="line">optimizer = tf.keras.optimizers.SGD(learning_rate=<span class="number">0.01</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        y_pred = model(X)      <span class="comment"># 调用模型 y_pred = model(X) 而不是显式写出 y_pred = a * X + b</span></span><br><span class="line">        loss = tf.reduce_mean(tf.square(y_pred - y))</span><br><span class="line">    grads = tape.gradient(loss, model.variables)    <span class="comment"># 使用 model.variables 这一属性直接获得模型中的所有变量</span></span><br><span class="line">    optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))</span><br><span class="line">print((model.variables),model.call(X))</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>编写个MLP即多层全连接的前馈神经网络，所看教程最后的数字识别</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MNISTLoader</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        mnist = tf.keras.datasets.mnist <span class="comment">#下面的load函数第一次会download  </span></span><br><span class="line">        (self.train_data,self.train_label),(self.test_data,self.test_label) = mnist.load_data()</span><br><span class="line">        <span class="comment"># MNIST中的图像默认为uint8（0-255的数字）。以下代码将其归一化到0-1之间的浮点数，并在最后增加一维作为颜色通道</span></span><br><span class="line">        self.train_data = np.expand_dims(self.train_data.astype(np.float32) / <span class="number">255.0</span>, axis=<span class="number">-1</span>)      <span class="comment"># [60000, 28, 28, 1]</span></span><br><span class="line">        self.test_data = np.expand_dims(self.test_data.astype(np.float32) / <span class="number">255.0</span>, axis=<span class="number">-1</span>)        <span class="comment"># [10000, 28, 28, 1]</span></span><br><span class="line">        self.train_label = self.train_label.astype(np.int32)    <span class="comment"># [60000]</span></span><br><span class="line">        self.test_label = self.test_label.astype(np.int32)      <span class="comment"># [10000]</span></span><br><span class="line">        self.num_train_data, self.num_test_data = self.train_data.shape[<span class="number">0</span>], self.test_data.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_batch</span><span class="params">(self, batch_size)</span>:</span></span><br><span class="line">        <span class="comment"># 从数据集中随机取出batch_size个元素并返回</span></span><br><span class="line">        index = np.random.randint(<span class="number">0</span>, np.shape(self.train_data)[<span class="number">0</span>], batch_size)<span class="comment">#返回列表</span></span><br><span class="line">        <span class="keyword">return</span> self.train_data[index, :], self.train_label[index]</span><br><span class="line">data = MNISTLoader()</span><br><span class="line"><span class="comment"># print(data.train_data[0][],data.train_label) #traindata=(6000,28,28)</span></span><br><span class="line"><span class="comment"># test = np.array([[1,2],[2,3]])</span></span><br><span class="line"><span class="comment"># print(np.expand_dims(test/5,axis=-1)) 这种操作结果增加一维度但实际不变，增加的一维就是替换掉原本</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MLP</span><span class="params">(tf.keras.Model)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().__init__() </span><br><span class="line">        self.flatten = tf.keras.layers.Flatten() <span class="comment"># Flatten层将除第一维（batch_size）以外的维度展平 用于输入层</span></span><br><span class="line">        self.dense1 = tf.keras.layers.Dense(units=<span class="number">256</span>,activation=tf.nn.relu)<span class="comment">#初始accuracy: 0.928500，loss=0.15</span></span><br><span class="line">        self.dense2 = tf.keras.layers.Dense(units=<span class="number">64</span>,activation=tf.nn.relu)<span class="comment">#加了这层后accuracy: 0.935200，loss降到了0.08，如果是sigmiod比初始还差</span></span><br><span class="line">        self.dense3 = tf.keras.layers.Dense(units=<span class="number">10</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self,inputs)</span>:</span></span><br><span class="line">        x = self.flatten(inputs)</span><br><span class="line">        x = self.dense1(x)</span><br><span class="line">        x = self.dense2(x)</span><br><span class="line">        x = self.dense3(x)</span><br><span class="line">        output = tf.nn.softmax(x)</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>mnist再用卷积神经网络来分类除了全连接层还有池化卷积，用时翻倍但准确率也高</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CNN</span><span class="params">(tf.keras.Model)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.conv1 = tf.keras.layers.Conv2D(</span><br><span class="line">            filters=<span class="number">32</span>,             <span class="comment"># 卷积层神经元（卷积核）数目</span></span><br><span class="line">            kernel_size=[<span class="number">5</span>, <span class="number">5</span>],     <span class="comment"># 感受野大小</span></span><br><span class="line">            padding=<span class="string">'same'</span>,         <span class="comment"># padding策略（vaild 或 same）</span></span><br><span class="line">            activation=tf.nn.relu   <span class="comment"># 激活函数</span></span><br><span class="line">        )</span><br><span class="line">        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=[<span class="number">2</span>, <span class="number">2</span>], strides=<span class="number">2</span>)</span><br><span class="line">        self.conv2 = tf.keras.layers.Conv2D(</span><br><span class="line">            filters=<span class="number">64</span>,</span><br><span class="line">            kernel_size=[<span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">            padding=<span class="string">'same'</span>,</span><br><span class="line">            activation=tf.nn.relu</span><br><span class="line">        )</span><br><span class="line">        self.pool2 = tf.keras.layers.MaxPool2D(pool_size=[<span class="number">2</span>, <span class="number">2</span>], strides=<span class="number">2</span>)</span><br><span class="line">        self.flatten = tf.keras.layers.Reshape(target_shape=(<span class="number">7</span> * <span class="number">7</span> * <span class="number">64</span>,))</span><br><span class="line">        self.dense1 = tf.keras.layers.Dense(units=<span class="number">1024</span>, activation=tf.nn.relu)</span><br><span class="line">        self.dense2 = tf.keras.layers.Dense(units=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, inputs)</span>:</span></span><br><span class="line">        x = self.conv1(inputs)                  <span class="comment"># [batch_size, 28, 28, 32]</span></span><br><span class="line">        x = self.pool1(x)                       <span class="comment"># [batch_size, 14, 14, 32]</span></span><br><span class="line">        x = self.conv2(x)                       <span class="comment"># [batch_size, 14, 14, 64]</span></span><br><span class="line">        x = self.pool2(x)                       <span class="comment"># [batch_size, 7, 7, 64]</span></span><br><span class="line">        x = self.flatten(x)                     <span class="comment"># [batch_size, 7 * 7 * 64]</span></span><br><span class="line">        x = self.dense1(x)                      <span class="comment"># [batch_size, 1024]</span></span><br><span class="line">        x = self.dense2(x)                      <span class="comment"># [batch_size, 10]</span></span><br><span class="line">        output = tf.nn.softmax(x)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#训练Mnist的方法，传入构造的模型</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trainMLP</span><span class="params">(model)</span>:</span>    </span><br><span class="line">    batch_size = <span class="number">100</span></span><br><span class="line">    num_epochs = <span class="number">3</span></span><br><span class="line">    learning_rate = <span class="number">0.008</span> <span class="comment">#调试各个参数提高准确率,在翻倍epoch后达到了97</span></span><br><span class="line">    <span class="comment"># model = Model()</span></span><br><span class="line">    data_loader = MNISTLoader()</span><br><span class="line">    opt = tf.keras.optimizers.Adam(learning_rate)</span><br><span class="line">    num_batches = int(data_loader.num_train_data // batch_size * num_epochs)</span><br><span class="line">    <span class="keyword">for</span> batch_index <span class="keyword">in</span> range(num_batches):</span><br><span class="line">        X, y = data_loader.get_batch(batch_size)</span><br><span class="line">        <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">            y_pred = model(X)</span><br><span class="line">            loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_pred)</span><br><span class="line">            loss = tf.reduce_mean(loss)</span><br><span class="line">            print(<span class="string">"batch %d: loss %f"</span> % (batch_index, loss.numpy()))</span><br><span class="line">        grads = tape.gradient(loss, model.variables)</span><br><span class="line">        opt.apply_gradients(grads_and_vars=zip(grads, model.variables))</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">metrics</span><span class="params">()</span>:</span></span><br><span class="line">        sparse_categorical_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()</span><br><span class="line">        num_batches = int(data_loader.num_test_data // batch_size)</span><br><span class="line">        <span class="keyword">for</span> batch_index <span class="keyword">in</span> range(num_batches):</span><br><span class="line">            start_index, end_index = batch_index * batch_size, (batch_index + <span class="number">1</span>) * batch_size</span><br><span class="line">            y_pred = model.predict(data_loader.test_data[start_index: end_index])</span><br><span class="line">            sparse_categorical_accuracy.update_state(y_true=data_loader.test_label[start_index: end_index], y_pred=y_pred)</span><br><span class="line">        print(<span class="string">"test accuracy: %f"</span> % sparse_categorical_accuracy.result())</span><br><span class="line">    metrics()        </span><br><span class="line"><span class="comment"># traincnn()</span></span><br><span class="line"><span class="comment"># print(model.variables)在训练前为空列表</span></span><br></pre></td></tr></table></figure>
<ol start="5">
<li><p>循环神经网络：文本处理，task以RNN生成尼采风格文本。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TextLoader</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        path = tf.keras.utils.get_file(<span class="string">'nietzsche.txt'</span>,</span><br><span class="line">            origin=<span class="string">'https://s3.amazonaws.com/text-datasets/nietzsche.txt'</span>)</span><br><span class="line">        <span class="keyword">with</span> open(path, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            self.raw_text = f.read().lower()</span><br><span class="line">        self.chars = sorted(list(set(self.raw_text)))</span><br><span class="line">        self.char_indices = dict((c, i) <span class="keyword">for</span> i, c <span class="keyword">in</span> enumerate(self.chars))</span><br><span class="line">        self.indices_char = dict((i, c) <span class="keyword">for</span> i, c <span class="keyword">in</span> enumerate(self.chars))</span><br><span class="line">        self.text = [self.char_indices[c] <span class="keyword">for</span> c <span class="keyword">in</span> self.raw_text]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_batch</span><span class="params">(self, seq_length, batch_size)</span>:</span></span><br><span class="line">        seq = []</span><br><span class="line">        next_char = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(batch_size):</span><br><span class="line">            index = np.random.randint(<span class="number">0</span>, len(self.text) - seq_length)</span><br><span class="line">            seq.append(self.text[index:index+seq_length])</span><br><span class="line">            next_char.append(self.text[index+seq_length])</span><br><span class="line">        <span class="keyword">return</span> np.array(seq), np.array(next_char)       <span class="comment"># [batch_size, seq_length], [num_batch]</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RNN</span><span class="params">(tf.keras.Model)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_chars, batch_size, seq_length)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.num_chars = num_chars</span><br><span class="line">        self.seq_length = seq_length</span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line">        self.cell = tf.keras.layers.LSTMCell(units=<span class="number">256</span>)</span><br><span class="line">        self.dense = tf.keras.layers.Dense(units=self.num_chars)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, inputs, from_logits=False)</span>:</span></span><br><span class="line">        inputs = tf.one_hot(inputs, depth=self.num_chars)       <span class="comment"># [batch_size, seq_length, num_chars]</span></span><br><span class="line">        state = self.cell.get_initial_state(batch_size=self.batch_size, dtype=tf.float32)</span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> range(self.seq_length):</span><br><span class="line">            output, state = self.cell(inputs[:, t, :], state)</span><br><span class="line">        logits = self.dense(output)</span><br><span class="line">        <span class="keyword">if</span> from_logits:</span><br><span class="line">            <span class="keyword">return</span> logits</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> tf.nn.softmax(logits)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, inputs, temperature=<span class="number">1.</span>)</span>:</span></span><br><span class="line">        batch_size, _ = tf.shape(inputs)</span><br><span class="line">        logits = self(inputs, from_logits=<span class="literal">True</span>)</span><br><span class="line">        prob = tf.nn.softmax(logits / temperature).numpy()</span><br><span class="line">        <span class="keyword">return</span> np.array([np.random.choice(self.num_chars, p=prob[i, :])</span><br><span class="line">                         <span class="keyword">for</span> i <span class="keyword">in</span> range(batch_size.numpy())])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trainRnn</span><span class="params">()</span>:</span></span><br><span class="line">    num_batches = <span class="number">1000</span></span><br><span class="line">    seq_length = <span class="number">40</span></span><br><span class="line">    batch_size = <span class="number">50</span></span><br><span class="line">    learning_rate = <span class="number">1e-3</span></span><br><span class="line">    data_loader = TextLoader()</span><br><span class="line">    model = RNN(num_chars=len(data_loader.chars), batch_size=batch_size, seq_length=seq_length)</span><br><span class="line">    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)</span><br><span class="line">    <span class="keyword">for</span> batch_index <span class="keyword">in</span> range(num_batches):</span><br><span class="line">        X, y = data_loader.get_batch(seq_length, batch_size)</span><br><span class="line">        <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">            y_pred = model(X)</span><br><span class="line">            loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_pred)</span><br><span class="line">            loss = tf.reduce_mean(loss)</span><br><span class="line">            print(<span class="string">"batch %d: loss %f"</span> % (batch_index, loss.numpy()))</span><br><span class="line">        grads = tape.gradient(loss, model.variables)</span><br><span class="line">        optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))</span><br><span class="line"></span><br><span class="line">    <span class="comment">#雪球式预测下个char</span></span><br><span class="line">    X_, _ = data_loader.get_batch(seq_length, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> diversity <span class="keyword">in</span> [<span class="number">0.2</span>, <span class="number">0.5</span>, <span class="number">1.0</span>, <span class="number">1.2</span>]:</span><br><span class="line">        X = X_</span><br><span class="line">        print(<span class="string">"diversity %f:"</span> % diversity)</span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">400</span>):</span><br><span class="line">            y_pred = model.predict(X, diversity)</span><br><span class="line">            print(data_loader.indices_char[y_pred[<span class="number">0</span>]], end=<span class="string">''</span>, flush=<span class="literal">True</span>)</span><br><span class="line">            X = np.concatenate([X[:, <span class="number">1</span>:], np.expand_dims(y_pred, axis=<span class="number">1</span>)], axis=<span class="number">-1</span>)</span><br><span class="line">        print(<span class="string">"\n"</span>)</span><br><span class="line">trainRnn()</span><br></pre></td></tr></table></figure>
</li>
<li><p>利用keras的高级api建立模型 sequential通过向 tf.keras.models.Sequential() 提供一个层的列表，就能快速地建立一个 tf.keras.Model 模型并返回：</p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    tf.keras.layers.Flatten(),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">100</span>,activation=tf.nn.sigmoid),</span><br><span class="line">    <span class="comment"># tf.keras.layers.Dense(64,activation=tf.nn.relu),</span></span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>),</span><br><span class="line">    tf.keras.layers.Softmax()</span><br><span class="line">    ])</span><br><span class="line"><span class="comment">#Keras 提供了 Functional API，帮助我们建立更为复杂的模型，例如多输入 / 输出或存在参数共享的模型</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">FunctionalCreate</span><span class="params">()</span>:</span></span><br><span class="line">    inputs = tf.keras.Input(shape=(<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>))</span><br><span class="line">    x = tf.keras.layers.Flatten()(inputs)</span><br><span class="line">    x = tf.keras.layers.Dense(units=<span class="number">100</span>, activation=tf.nn.relu)(x)</span><br><span class="line">    x = tf.keras.layers.Dense(units=<span class="number">10</span>)(x)</span><br><span class="line">    outputs = tf.keras.layers.Softmax()(x)</span><br><span class="line">    model = tf.keras.Model(inputs=inputs, outputs=outputs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"><span class="comment"># trainMLP(MLP())</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">apitrain</span><span class="params">()</span>:</span></span><br><span class="line">    model = MLP()</span><br><span class="line">    <span class="comment">#使用kerasmodel的三个方法训练和评估</span></span><br><span class="line">    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=<span class="number">0.001</span>)</span><br><span class="line">        ,loss=tf.keras.losses.sparse_categorical_crossentropy</span><br><span class="line">        ,metrics=[tf.keras.metrics.sparse_categorical_accuracy])</span><br><span class="line">    <span class="comment">#complle接受 优化器，损失函数，评估指标都从对应的类里选</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    model.fit(MNISTLoader().train_data,MNISTLoader().train_label,epochs=<span class="number">3</span>,batch_size=<span class="number">100</span>)</span><br><span class="line">    <span class="comment">#返回列表包含最终loss和accuracy 在这里测试之前的模型准确率都上升了</span></span><br><span class="line">    print(<span class="string">'\n'</span>,model.evaluate(MNISTLoader().test_data,MNISTLoader().test_label))</span><br><span class="line">apitrain()</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Tensorflow</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
</search>
