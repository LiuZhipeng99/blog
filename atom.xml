<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>There for You</title>
  
  <subtitle>keep loving the world</subtitle>
  <link href="/blog/atom.xml" rel="self"/>
  
  <link href="https://kivid.github.io/"/>
  <updated>2020-06-01T14:33:41.470Z</updated>
  <id>https://kivid.github.io/</id>
  
  <author>
    <name>友達A</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>FOR LYX</title>
    <link href="https://kivid.github.io/2020/06/01/FOR-LYX/"/>
    <id>https://kivid.github.io/2020/06/01/FOR-LYX/</id>
    <published>2020-06-01T14:04:12.000Z</published>
    <updated>2020-06-01T14:33:41.470Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\blog\assets\js\Meting.min.js"></script><p>没错就是这个</p><a id="more"></a><p>   好久不见，这么说有点古怪，还不知道什么时候能见着呢.写到这里千言万语化作一，化作胡言乱语:<br>去年春晓在学校的银杏大道边，读了何潇安利的一本村上春树的作品，没有色彩的多琦作和他的巡年之礼。让我觉得就算是没有见过面的人也能通过书信往来，真是个奇迹。<br>这两年对我来说改变巨大，让我感觉我现在都能去996，签下奋斗者协议了（哈哈，是不是反讽细品）。很遗憾没有幻想的多彩生活，要做的事情多，要学的也多。之前做项目遇到过大佬，竟然也是来着四川，甚至离我们很近，嘴里念叨着，四川人出白帝成龙，一路沿着大佬方向奔去。暗自感叹之余也许也迸发出激情来。两年很短了，不知道那时我在做实习生还是研究生，回过头来，就会发现这段时间原来做了那么多事，并非枯燥而迸发光芒。就像现在回望过去一样。</p><p>写到这里，不得不插一句，在没有共同经历的世界里，想写没有交叉的东西太难了！尽管初时感觉有意义，但越写越怀疑，这么无聊的东西，真是浪费别人时间。毕竟20th，还是坚持到底了。<br>听说聊天技巧之一就是别一直说自己，但我真的找不到其他点！而且博客写多了难从说明风格转变回来<br>那么试着加入些宾语。<br>不知你现在在干嘛，不知你身边是否有那个人，不知你变得怎样。。。<br>没有共通点的都是伪物（某位大老师说的）。<br>18年十月是离你最近的时间段，当时不知道说过没有，我感觉咱们一生说过的话大多就在那些皓月当空的夜晚，我也是现在才明白为了避免沉默一直说自己（看到这里你可能会想 你明白个泡泡茶壶），但其实只有在乎的人才会认真听，不交心可别。记得当时电话那边在滔滔不绝说着那教官教官时我心说没了没了（现在不知你们后来如何）<br>  上个星期开学了，可大伙大多没开学，回来面对的是考试、ddl、实验等混合物<br>也中过大奖，有次晚会上中了个锦鲤大奖（也许花光了我一生的欧气）<br>也有了新喜欢的歌手（八爷）<br>也结识了前路的学长，也许就不读研了而下功夫走华为秋招。<br>也终于敢在过百人的舞台上了<br>懂得了我们这行越早下功夫越好（以后大概我会应聘算法工程师），我选择这个专业原因之一就是早定位早就业，而且工资顶。</p><p>这些特殊的日子里，我不知是否我的用心都被发现（高二那次不知道发现没有），但我是每次高兴得不得了。<br>我很抱歉以前传递给你的负能量，就这一次（很可能最后一次）我希望能带来好的东西。</p><p>  今年12月那天我就知道了，也许是不想与我有来往了，或者说不想承受什么了。当时我也想明白了，但好几年如常，日子到了就像冬天到了熊会打瞌睡一样。刚好和我生辰差6个月，不知道注意没有，，去年留的彩蛋不知道发现没有，其实就是一段录音和生日歌。也不知道操作是不是复杂了点，这次就简简单单结尾吧 。</p><p>  本该收到暗示，自行了去，暗自琢磨着，万一不是呢，厚着脸皮写下这些。毕竟二十而立的嘛，挺混乱的写的，但能传达到就好了。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;没错就是这个&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>折腾VPS</title>
    <link href="https://kivid.github.io/2020/05/14/%E6%8A%98%E8%85%BEVPS/"/>
    <id>https://kivid.github.io/2020/05/14/%E6%8A%98%E8%85%BEVPS/</id>
    <published>2020-05-14T02:30:19.000Z</published>
    <updated>2020-05-17T14:41:05.217Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\blog\assets\js\Meting.min.js"></script><p>近日选购了个超便宜的VPS（趁着五月优惠）。于是尝试了些爱国技术，也作为VPS路上的踩坑。</p><a id="more"></a><h4 id="VPS选购与测试"><a href="#VPS选购与测试" class="headerlink" title="VPS选购与测试"></a>VPS选购与测试</h4><p>  简单提两点就是。虚拟化最好是KVM，另外的基本都是虚拟操作系统等等，无法自由安装系统更改内核。</p><p>另一点就是CN-2等四个电信线路，如果有的话会标识，也更贵相当于更优线路。</p><p>测试方面io，speedtest，ping等可利用网上的测试shell和网站。</p><p><a href="https://www.mrkevin.net/share/1383.html" target="_blank" rel="noopener">https://www.mrkevin.net/share/1383.html</a>这是测试工具位置。</p><h4 id="为了自由"><a href="#为了自由" class="headerlink" title="为了自由"></a>为了自由</h4><p>  之前学校用过SS没人合租了有点贵也就没续费。最近用完了蓝灯500M，发现自由这种东西，一旦触碰到了就难以拒绝，就像艾伦一样，看见城墙就想出去，看见大海就想越过。</p><p>当然，只是查资料用插件的话下个‘谷歌助手’的插件足矣。</p><p>  在ss作者和ssr作者被请去喝茶后，用的人越来越少了，而且侦测也越来越针对，近年来v2ray和trojan更加适合，前者可建立转发隧道或者ws+tls来伪装站点（油管上波仔分享），后者也能伪装http协议。在运输层和应用层，虽然速度可能慢点了但安全性大大提升。如何安装网上一键脚本非常多（可以看波仔分享），另外BBR内核是一种具有拥塞控制算法的内核，由谷歌开源。它们在github上都有项目，有时候晚上国内github下载特慢。</p><p>​    在SS上畅游了不一会发现日志一直time out了，但ping能通，本以为网速问题，tcp延时无限大，这应该是tcp阻断了，ss可以重置个端口还能用下，一会又不行了，上工具网站ping，发现只有国内tcp不可用，大概就是TCP阻断了。但好在ip能用于是从ss转到trojan，这个东西需要个域名解析到服务器，找了会免费域名太麻烦就用v2ray，当时是晚高峰实在下不了客户端，还得下个core和gui。</p><p>  梯子没问题后，还能通过端口转发利用国内vps，也可使用机场的隧道转发，但我那华为云也不咋快。要做可以用dobi大神的脚本来配置。</p><p>  这两年来总共开了三个VPS，第一年阿里云的域名加学生机，相当浪费的一年。第二年趁着牛客网活动9.9入手了一年华为云,而这次是第一次租外网VPS，因为看评测看到这款$6.5每年的心动了，这家服务商就是<em>pacificrack.com_。每月42/12比学生机9.9都好得多！当时就上头冲了，刚刚下单就觉得不对劲，怕他跑路就查了查大伙反应，越看越心慌，发来份右键里面有控制面板和各项密码。结果ssh和ping上不了，在发工单和退款申请后，回执一份_The service will be cancelled at the end of your current billing period on 05/12/2021.</em></p><p>吐槽这时限同时只能等，半天后回复工单是：之前没有实例化。（这也比网上说几天不回复让人安心多了）。意思是我之前控制面板一通重启，设置，重装半天都是对空气操作，面板online也不真实。之前显示空间0kb并且unavailable的时候就该停手。</p><p>在他们给VPS实例化后可以ssh登录了（说是5分钟就可用结果发工单才行奥）。</p><p>经历安装BBR，ss，ssr，v2ray，trojan，宝塔，lnmp等包都有死机情况，需要boot。</p><p>性能方面也通过上面的shell程序测试了，看着面板上500g用百分之一结果发现10g，本想当云盘还是算了装个探针算了。（bt老是报没有python.h的错）</p><p>除了头两三天折腾好了代理，这会又进入更高层次，怎么更安全，GFW怎么来的，几种阻断方式（上次可能ss被识别端口阻断，我这段敏感期还是关机度过怕被盯上了）</p><p>5.17</p><p>一键安装v2ray》》配置文件大意》》debian好处》》ws协议》》ws+tls伪装》》域名注册与dns》》国内vps转发-cnd转发（IP被封）</p><p>既然已经被 ban 了，直接 ssh 连接是连不上的，而使用本教程必须要 ssh 登录你的 VPS，以下有几种办法，可以解决这个问题：</p><ul><li>使用商家提供的网页 ssh 或 vnc 连接 VPS</li><li>使用一个可用的代理，通过此代理 ssh 连接 VPS</li><li>使用一个未被 ban 的境外服务器，ssh 登录此服务器，并在此服务器中继续使用 ssh 登录被 ban 的 VPS</li></ul><p>PS：注意到千万别国内DNS，一是要备案二是它能解析你流量。（注册的免费域名不备案得ssl证书https才能用）</p><p>新域名浏览器访问就给你阻断了（大概是DNS）</p><p>这里研究了下如何绕过备案：1。最安全是使用强制https跳转2。启用其他端口需要在nginx配置文件改3。cdn（这里cf的话其实会很慢，它把域名解析到它cdn服务器再转解析值）或者其他cdn</p><p>未来打算重装系统搞伪装加转发，就可以试试ss行不行，使用防火墙端口转发流量效率高</p><p>转发前2.2M/s </p><p>转发后1.7M/s 可能是到了10点晚高峰。。。虽然ping小了但tcpping依然200多</p><p>1.学会了Linux控制防火墙命令：addport，（addport用特定ip修饰）很多操作permanent一定要加，firewalld这个包的启动 状态 自启 list -cmd工具 端口转发配置，（！！一定要加伪装参数为yes）</p><p>ss -ntlp查看套字节占用。（发现防火墙转发不需要占用，nginx转发应该需要）</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;近日选购了个超便宜的VPS（趁着五月优惠）。于是尝试了些爱国技术，也作为VPS路上的踩坑。&lt;/p&gt;
    
    </summary>
    
    
      <category term="折腾" scheme="https://kivid.github.io/categories/%E6%8A%98%E8%85%BE/"/>
    
    
      <category term="VPS" scheme="https://kivid.github.io/tags/VPS/"/>
    
  </entry>
  
  <entry>
    <title>浅析网易云API</title>
    <link href="https://kivid.github.io/2020/05/09/%E6%B5%85%E6%9E%90%E7%BD%91%E6%98%93%E4%BA%91API/"/>
    <id>https://kivid.github.io/2020/05/09/%E6%B5%85%E6%9E%90%E7%BD%91%E6%98%93%E4%BA%91API/</id>
    <published>2020-05-09T05:49:54.000Z</published>
    <updated>2020-05-10T10:20:54.432Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\blog\assets\js\Meting.min.js"></script><p>  之前用网易云歌单放的外链不给力（版权问题放不了），于是想到换成diygod大神的Aplayer，但需要我们自己提供url，这里还是针对了网易云，其他平台api自行查找。</p><p>  本文主要做一个基于网易云API的H5音乐播放器。</p><a id="more"></a><h4 id="浅析API"><a href="#浅析API" class="headerlink" title="浅析API"></a>浅析API</h4><p>  做过爬虫都都知道API是个多么好用的东西，要想得到网易云其音乐的播放url，也就是直接获取MP4文件，还是经过API获取。此时通过Web请求来抓包显得至关重要。<br>    要想在网页端听歌，肯定是先搜索歌名再选择播放，这个过程最少有两次HTTP请求，第一次是输入歌名post请求得到歌曲ID，选择播放也是根据ID获得源文件播放地址。于是我们针对这两个过程抓包。</p><h4 id="抓包解析API"><a href="#抓包解析API" class="headerlink" title="抓包解析API"></a>抓包解析API</h4><p><img src="data:image/png;base64,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" data-original="./../../../../image/api1.png" alt=""></p><p>​    可见这条是请求id的请求，其url为_<a href="https://music.163.com/weapi/search/suggest/web?csrf_token=2e7122a2e61c28a25847250ee1524c2b_更关键的是post字段" target="_blank" rel="noopener">https://music.163.com/weapi/search/suggest/web?csrf_token=2e7122a2e61c28a25847250ee1524c2b_更关键的是post字段</a></p><p><img src="data:image/png;base64,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" data-original="./../../../../image/api2.png" alt="1589003911544"></p><p>​    post有两个字段params和encSecKey，这猜测是AES加密，于是网上看看怎么加密的，果然网上有人总结了了但现今已经不一样了，遵循其过程也可以解码但这里有个更方便的方法，因为有人已经做出放在网站上了，<a href="https://music.liuzhijin.cn/" target="_blank" rel="noopener">刘志进-音乐直链搜索</a>（其他平台也可以直接来抓）。于是在这个网站上抓包看看，果然比某云云简单明了多了。</p><p><img src="data:image/png;base64,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" data-original="./../../../../image/api3.png" alt="1589004500510"></p><p><img src="data:image/png;base64,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" data-original="./../../../../image/api4.png" alt="1589004500510"></p><p>到这里就可以用脚本得到播放地址了。下面再提下其他的。</p><p><a href="http://music.163.com/api/song/enhance/player/url?id=518686034&ids=[123456]&br=3200000" target="_blank" rel="noopener">http://music.163.com/api/song/enhance/player/url?id=518686034&amp;ids=%5B123456%5D&amp;br=3200000</a>。点进去就可以看到，返回Json字段的各个参数，url并且和上面那个不同，可以备用。（PS：网易云没版权还是没办法）</p><h4 id="获取歌曲其他信息"><a href="#获取歌曲其他信息" class="headerlink" title="获取歌曲其他信息"></a>获取歌曲其他信息</h4><ul><li>获取url任务完成，此时想得到cover等歌曲信息：</li></ul><p>URL：GET  <a href="http://music.163.com/api/song/detail/" target="_blank" rel="noopener">http://music.163.com/api/song/detail/</a></p><p>必要参数：id：歌曲ID ids：不知道干什么用的，用[]括起来的歌曲ID</p><p>如 <a href="http://music.163.com/api/song/detail/?id=28377211&amp;ids=%5B28377211%5D" target="_blank" rel="noopener">http://music.163.com/api/song/detail/?id=28377211&amp;ids=%5B28377211%5D</a></p><p>更详细的：<a href="http://music.163.com/api/playlist/detail?id=37880978&amp;updateTime=-1" target="_blank" rel="noopener">http://music.163.com/api/playlist/detail?id=37880978&amp;updateTime=-1</a></p><ul><li><p>歌词： <a href="http://music.163.com/api/song/lyric?os=pc&id=85580&lv=-1&kv=-1&tv=-1" target="_blank" rel="noopener">http://music.163.com/api/song/lyric?os=pc&amp;id=85580&amp;lv=-1&amp;kv=-1&amp;tv=-1</a></p></li><li><p>歌单：URL：GET <a href="http://music.163.com/api/playlist/detail" target="_blank" rel="noopener">http://music.163.com/api/playlist/detail</a></p><p>必要参数：id：歌单ID</p><p>例如：<a href="http://music.163.com/api/playlist/detail?id=37880978&amp;updateTime=-1" target="_blank" rel="noopener">http://music.163.com/api/playlist/detail?id=37880978&amp;updateTime=-1</a></p></li></ul><h4 id="意外发现个非主流平台—MyFreeMP3"><a href="#意外发现个非主流平台—MyFreeMP3" class="headerlink" title="意外发现个非主流平台—MyFreeMP3"></a>意外发现个非主流平台—<a href="[http://tool.liumingye.cn](http://tool.liumingye.cn/)">MyFreeMP3</a></h4><p>​    应该是歌曲比那些要版权的主流多谢，随便抓下包发现也挺直接的。</p><p><img src="data:image/png;base64,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" data-original="./../../../../image/api5.png" alt="1589004500510"></p><hr><p>至此可用Aplayer创建个H5音乐播放器了，下篇有机会写这个的应用</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;  之前用网易云歌单放的外链不给力（版权问题放不了），于是想到换成diygod大神的Aplayer，但需要我们自己提供url，这里还是针对了网易云，其他平台api自行查找。&lt;/p&gt;
&lt;p&gt;  本文主要做一个基于网易云API的H5音乐播放器。&lt;/p&gt;
    
    </summary>
    
    
      <category term="折腾" scheme="https://kivid.github.io/categories/%E6%8A%98%E8%85%BE/"/>
    
    
      <category term="blog" scheme="https://kivid.github.io/tags/blog/"/>
    
      <category term="API" scheme="https://kivid.github.io/tags/API/"/>
    
  </entry>
  
  <entry>
    <title>Tensorflow学习笔记(一）</title>
    <link href="https://kivid.github.io/2020/05/08/tensorflow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>https://kivid.github.io/2020/05/08/tensorflow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/</id>
    <published>2020-05-08T09:37:31.000Z</published>
    <updated>2020-05-08T09:46:48.931Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\blog\assets\js\Meting.min.js"></script><p>  学习tensorflow的经验和总结</p><a id="more"></a><blockquote><p>想学习tf的人，或许啃完了网上的机器学习课程（吴恩达），或许正在上学校里的机器学习课程，抑或是只解皮毛而想快速入门。<br>学前建议：<br> 1.对于没有任何基础的兄台还是老老实实的回去看看高数，不然走不下去。<br> 2.对于正在学机器学习的人来说，你或许已经了解梯度下降，知道若干种损失函数激活函数，但建议先自己动手做网络构建走基础路线。例如吴恩达课程和本人<a href="https://github.com/microsoft/ai-edu/tree/master/A-%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B" target="_blank" rel="noopener">用的</a>（基于python）。<br> 3.对于基础扎实的同学来说，tf将会是你大有作为的舞台。尽管去看那些网上丰富的文档相信你不会迷路。</p></blockquote><h4 id="关于搭建环境"><a href="#关于搭建环境" class="headerlink" title="关于搭建环境"></a>关于搭建环境</h4><p>  如果是初学TF建议使用cpu版本，这样省去诸多麻烦。例如gpu版本需要电脑gpu支持（nividia，需要驱动），并且安装cuDnn和cudatoolkit（需要和tensorflow版本对应），另外python高版本还未适配tensorflow所以不能安装过高版本，此时anaconda闪亮登场，它不仅能虚拟环境让py、包等与系统隔离开，指定python版本和自动下相应cuda搭配。当然如果用cpu版本无需考虑。</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">print(tf.__version__) <span class="comment">#打印即成功</span></span><br></pre></td></tr></table></figure><h4 id="关于keras和tf-keras"><a href="#关于keras和tf-keras" class="headerlink" title="关于keras和tf.keras"></a>关于keras和tf.keras</h4><p>  现在都是直接下载tensorflow里面内置了keras，官方也推荐使用后者，相当于后者是将其收纳了，实际上关系是：tensorflow作为其计算工具，后者是tensorflow的高级api，简单来说就是协作关系，keras是只笔，tensorflow是张纸。</p><h4 id="初识Tensorflow"><a href="#初识Tensorflow" class="headerlink" title="初识Tensorflow"></a>初识Tensorflow</h4><blockquote><p>前馈神经网络：<strong>分为多层, 相邻层之间全连接, 不存在同层连接与跨层连接</strong>. 整个网络中无反馈，可用一个有向无环图表示.用标准bp算法训练（基于SDG）。</p><p>以下从特性到建立模型和训练。从代码实战开始</p></blockquote><ol><li>了解其特效和基础–自动求导机制</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">x = tf.Variable(initial_value=<span class="number">3.</span>)</span><br><span class="line"><span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">  y = <span class="number">3</span>*tf.square(x)</span><br><span class="line">  z = y+<span class="number">3</span>*x</span><br><span class="line">z_grad = tape.gradient(z,x)</span><br><span class="line">print(y,z,z_grad)</span><br><span class="line"><span class="comment">#利用其求偏导</span></span><br><span class="line">X = tf.constant([[<span class="number">1.</span>, <span class="number">2.</span>], [<span class="number">3.</span>, <span class="number">4.</span>]])</span><br><span class="line">y = tf.constant([[<span class="number">1.</span>], [<span class="number">2.</span>]])</span><br><span class="line">w = tf.Variable(initial_value=[[<span class="number">1.</span>], [<span class="number">2.</span>]])</span><br><span class="line">b = tf.Variable(initial_value=<span class="number">1.</span>)</span><br><span class="line"><span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">    L = tf.reduce_sum(tf.square(tf.matmul(X, w) + b - y))</span><br><span class="line">w_grad, b_grad = tape.gradient(L, [w, b])        <span class="comment"># 计算L(w, b)关于w, b的偏导数</span></span><br><span class="line">print(L, w_grad, b_grad)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 线性回归示例：生成data</span></span><br><span class="line">X_raw = np.array([<span class="number">2013</span>, <span class="number">2014</span>, <span class="number">2015</span>, <span class="number">2016</span>, <span class="number">2017</span>], dtype=np.float32)</span><br><span class="line">y_raw = np.array([<span class="number">12000</span>, <span class="number">14000</span>, <span class="number">15000</span>, <span class="number">16500</span>, <span class="number">17500</span>], dtype=np.float32)</span><br><span class="line"></span><br><span class="line">X = (X_raw - X_raw.min()) / (X_raw.max() - X_raw.min())</span><br><span class="line">y = (y_raw - y_raw.min()) / (y_raw.max() - y_raw.min())</span><br><span class="line">X = tf.constant(X)</span><br><span class="line">y = tf.constant(y)</span><br><span class="line"></span><br><span class="line">a = tf.Variable(initial_value=<span class="number">0.</span>)</span><br><span class="line">b = tf.Variable(initial_value=<span class="number">0.</span>)</span><br><span class="line">variables=[a,b]</span><br><span class="line">num_epoch = <span class="number">10000</span></span><br><span class="line">opt = tf.keras.optimizers.SGD(learning_rate=<span class="number">5e-4</span>)</span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> range(num_epoch):</span><br><span class="line">  <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">      y_pred = a * X + b</span><br><span class="line">      loss = tf.reduce_sum(tf.square(y_pred-y))</span><br><span class="line">  grads = tape.gradient(loss,variables)</span><br><span class="line">  opt.apply_gradients(grads_and_vars=zip(grads,variables))</span><br><span class="line">print(a,b)</span><br></pre></td></tr></table></figure><ol start="2"><li>创建自己的模型作用如上面的运算和variable（下面的方法都是各类框架通用，没有使用高级api，都是自定义网络）</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModel</span><span class="params">(tf.keras.Model)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().__init__()     <span class="comment"># Python 2 下使用 super(MyModel, self).__init__()</span></span><br><span class="line">        <span class="comment"># 此处添加初始化代码（包含 call 方法中会用到的层），例如</span></span><br><span class="line">        <span class="comment"># layer1 = tf.keras.layers.BuiltInLayer(...)</span></span><br><span class="line">        <span class="comment"># layer2 = MyCustomLayer(...)</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, input)</span>:</span></span><br><span class="line">        <span class="comment"># 此处添加模型调用的代码（处理输入并返回输出），例如</span></span><br><span class="line">        <span class="comment"># x = layer1(input)</span></span><br><span class="line">        <span class="comment"># output = layer2(x)</span></span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 还可以添加自定义的方法</span></span><br><span class="line"><span class="comment">#由于继承自model其有variable这一属性获取所有变量</span></span><br><span class="line"><span class="comment">#将上例的y=ax+b模型化</span></span><br><span class="line">X = tf.constant([[<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>], [<span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">6.0</span>]])</span><br><span class="line">y = tf.constant([[<span class="number">10.0</span>], [<span class="number">20.0</span>]])</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Linear</span><span class="params">(tf.keras.Model)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.dense = tf.keras.layers.Dense(</span><br><span class="line">            units = <span class="number">1</span>,</span><br><span class="line">            activation=<span class="literal">None</span>,</span><br><span class="line">            kernel_initializer=tf.zeros_initializer(),</span><br><span class="line">            bias_initializer=tf.zeros_initializer()</span><br><span class="line"></span><br><span class="line">            )</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self,input)</span>:</span></span><br><span class="line">        output = self.dense(input)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">model = Linear()</span><br><span class="line">optimizer = tf.keras.optimizers.SGD(learning_rate=<span class="number">0.01</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        y_pred = model(X)      <span class="comment"># 调用模型 y_pred = model(X) 而不是显式写出 y_pred = a * X + b</span></span><br><span class="line">        loss = tf.reduce_mean(tf.square(y_pred - y))</span><br><span class="line">    grads = tape.gradient(loss, model.variables)    <span class="comment"># 使用 model.variables 这一属性直接获得模型中的所有变量</span></span><br><span class="line">    optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))</span><br><span class="line">print((model.variables),model.call(X))</span><br></pre></td></tr></table></figure><ol start="3"><li>编写个MLP即多层全连接的前馈神经网络，所看教程最后的数字识别</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MNISTLoader</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        mnist = tf.keras.datasets.mnist <span class="comment">#下面的load函数第一次会download  </span></span><br><span class="line">        (self.train_data,self.train_label),(self.test_data,self.test_label) = mnist.load_data()</span><br><span class="line">        <span class="comment"># MNIST中的图像默认为uint8（0-255的数字）。以下代码将其归一化到0-1之间的浮点数，并在最后增加一维作为颜色通道</span></span><br><span class="line">        self.train_data = np.expand_dims(self.train_data.astype(np.float32) / <span class="number">255.0</span>, axis=<span class="number">-1</span>)      <span class="comment"># [60000, 28, 28, 1]</span></span><br><span class="line">        self.test_data = np.expand_dims(self.test_data.astype(np.float32) / <span class="number">255.0</span>, axis=<span class="number">-1</span>)        <span class="comment"># [10000, 28, 28, 1]</span></span><br><span class="line">        self.train_label = self.train_label.astype(np.int32)    <span class="comment"># [60000]</span></span><br><span class="line">        self.test_label = self.test_label.astype(np.int32)      <span class="comment"># [10000]</span></span><br><span class="line">        self.num_train_data, self.num_test_data = self.train_data.shape[<span class="number">0</span>], self.test_data.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_batch</span><span class="params">(self, batch_size)</span>:</span></span><br><span class="line">        <span class="comment"># 从数据集中随机取出batch_size个元素并返回</span></span><br><span class="line">        index = np.random.randint(<span class="number">0</span>, np.shape(self.train_data)[<span class="number">0</span>], batch_size)<span class="comment">#返回列表</span></span><br><span class="line">        <span class="keyword">return</span> self.train_data[index, :], self.train_label[index]</span><br><span class="line">data = MNISTLoader()</span><br><span class="line"><span class="comment"># print(data.train_data[0][],data.train_label) #traindata=(6000,28,28)</span></span><br><span class="line"><span class="comment"># test = np.array([[1,2],[2,3]])</span></span><br><span class="line"><span class="comment"># print(np.expand_dims(test/5,axis=-1)) 这种操作结果增加一维度但实际不变，增加的一维就是替换掉原本</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MLP</span><span class="params">(tf.keras.Model)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().__init__() </span><br><span class="line">        self.flatten = tf.keras.layers.Flatten() <span class="comment"># Flatten层将除第一维（batch_size）以外的维度展平 用于输入层</span></span><br><span class="line">        self.dense1 = tf.keras.layers.Dense(units=<span class="number">256</span>,activation=tf.nn.relu)<span class="comment">#初始accuracy: 0.928500，loss=0.15</span></span><br><span class="line">        self.dense2 = tf.keras.layers.Dense(units=<span class="number">64</span>,activation=tf.nn.relu)<span class="comment">#加了这层后accuracy: 0.935200，loss降到了0.08，如果是sigmiod比初始还差</span></span><br><span class="line">        self.dense3 = tf.keras.layers.Dense(units=<span class="number">10</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self,inputs)</span>:</span></span><br><span class="line">        x = self.flatten(inputs)</span><br><span class="line">        x = self.dense1(x)</span><br><span class="line">        x = self.dense2(x)</span><br><span class="line">        x = self.dense3(x)</span><br><span class="line">        output = tf.nn.softmax(x)</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure><ol start="4"><li>mnist再用卷积神经网络来分类除了全连接层还有池化卷积，用时翻倍但准确率也高</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CNN</span><span class="params">(tf.keras.Model)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.conv1 = tf.keras.layers.Conv2D(</span><br><span class="line">            filters=<span class="number">32</span>,             <span class="comment"># 卷积层神经元（卷积核）数目</span></span><br><span class="line">            kernel_size=[<span class="number">5</span>, <span class="number">5</span>],     <span class="comment"># 感受野大小</span></span><br><span class="line">            padding=<span class="string">'same'</span>,         <span class="comment"># padding策略（vaild 或 same）</span></span><br><span class="line">            activation=tf.nn.relu   <span class="comment"># 激活函数</span></span><br><span class="line">        )</span><br><span class="line">        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=[<span class="number">2</span>, <span class="number">2</span>], strides=<span class="number">2</span>)</span><br><span class="line">        self.conv2 = tf.keras.layers.Conv2D(</span><br><span class="line">            filters=<span class="number">64</span>,</span><br><span class="line">            kernel_size=[<span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">            padding=<span class="string">'same'</span>,</span><br><span class="line">            activation=tf.nn.relu</span><br><span class="line">        )</span><br><span class="line">        self.pool2 = tf.keras.layers.MaxPool2D(pool_size=[<span class="number">2</span>, <span class="number">2</span>], strides=<span class="number">2</span>)</span><br><span class="line">        self.flatten = tf.keras.layers.Reshape(target_shape=(<span class="number">7</span> * <span class="number">7</span> * <span class="number">64</span>,))</span><br><span class="line">        self.dense1 = tf.keras.layers.Dense(units=<span class="number">1024</span>, activation=tf.nn.relu)</span><br><span class="line">        self.dense2 = tf.keras.layers.Dense(units=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, inputs)</span>:</span></span><br><span class="line">        x = self.conv1(inputs)                  <span class="comment"># [batch_size, 28, 28, 32]</span></span><br><span class="line">        x = self.pool1(x)                       <span class="comment"># [batch_size, 14, 14, 32]</span></span><br><span class="line">        x = self.conv2(x)                       <span class="comment"># [batch_size, 14, 14, 64]</span></span><br><span class="line">        x = self.pool2(x)                       <span class="comment"># [batch_size, 7, 7, 64]</span></span><br><span class="line">        x = self.flatten(x)                     <span class="comment"># [batch_size, 7 * 7 * 64]</span></span><br><span class="line">        x = self.dense1(x)                      <span class="comment"># [batch_size, 1024]</span></span><br><span class="line">        x = self.dense2(x)                      <span class="comment"># [batch_size, 10]</span></span><br><span class="line">        output = tf.nn.softmax(x)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#训练Mnist的方法，传入构造的模型</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trainMLP</span><span class="params">(model)</span>:</span>    </span><br><span class="line">    batch_size = <span class="number">100</span></span><br><span class="line">    num_epochs = <span class="number">3</span></span><br><span class="line">    learning_rate = <span class="number">0.008</span> <span class="comment">#调试各个参数提高准确率,在翻倍epoch后达到了97</span></span><br><span class="line">    <span class="comment"># model = Model()</span></span><br><span class="line">    data_loader = MNISTLoader()</span><br><span class="line">    opt = tf.keras.optimizers.Adam(learning_rate)</span><br><span class="line">    num_batches = int(data_loader.num_train_data // batch_size * num_epochs)</span><br><span class="line">    <span class="keyword">for</span> batch_index <span class="keyword">in</span> range(num_batches):</span><br><span class="line">        X, y = data_loader.get_batch(batch_size)</span><br><span class="line">        <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">            y_pred = model(X)</span><br><span class="line">            loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_pred)</span><br><span class="line">            loss = tf.reduce_mean(loss)</span><br><span class="line">            print(<span class="string">"batch %d: loss %f"</span> % (batch_index, loss.numpy()))</span><br><span class="line">        grads = tape.gradient(loss, model.variables)</span><br><span class="line">        opt.apply_gradients(grads_and_vars=zip(grads, model.variables))</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">metrics</span><span class="params">()</span>:</span></span><br><span class="line">        sparse_categorical_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()</span><br><span class="line">        num_batches = int(data_loader.num_test_data // batch_size)</span><br><span class="line">        <span class="keyword">for</span> batch_index <span class="keyword">in</span> range(num_batches):</span><br><span class="line">            start_index, end_index = batch_index * batch_size, (batch_index + <span class="number">1</span>) * batch_size</span><br><span class="line">            y_pred = model.predict(data_loader.test_data[start_index: end_index])</span><br><span class="line">            sparse_categorical_accuracy.update_state(y_true=data_loader.test_label[start_index: end_index], y_pred=y_pred)</span><br><span class="line">        print(<span class="string">"test accuracy: %f"</span> % sparse_categorical_accuracy.result())</span><br><span class="line">    metrics()        </span><br><span class="line"><span class="comment"># traincnn()</span></span><br><span class="line"><span class="comment"># print(model.variables)在训练前为空列表</span></span><br></pre></td></tr></table></figure><ol start="5"><li><p>循环神经网络：文本处理，task以RNN生成尼采风格文本。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TextLoader</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        path = tf.keras.utils.get_file(<span class="string">'nietzsche.txt'</span>,</span><br><span class="line">            origin=<span class="string">'https://s3.amazonaws.com/text-datasets/nietzsche.txt'</span>)</span><br><span class="line">        <span class="keyword">with</span> open(path, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            self.raw_text = f.read().lower()</span><br><span class="line">        self.chars = sorted(list(set(self.raw_text)))</span><br><span class="line">        self.char_indices = dict((c, i) <span class="keyword">for</span> i, c <span class="keyword">in</span> enumerate(self.chars))</span><br><span class="line">        self.indices_char = dict((i, c) <span class="keyword">for</span> i, c <span class="keyword">in</span> enumerate(self.chars))</span><br><span class="line">        self.text = [self.char_indices[c] <span class="keyword">for</span> c <span class="keyword">in</span> self.raw_text]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_batch</span><span class="params">(self, seq_length, batch_size)</span>:</span></span><br><span class="line">        seq = []</span><br><span class="line">        next_char = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(batch_size):</span><br><span class="line">            index = np.random.randint(<span class="number">0</span>, len(self.text) - seq_length)</span><br><span class="line">            seq.append(self.text[index:index+seq_length])</span><br><span class="line">            next_char.append(self.text[index+seq_length])</span><br><span class="line">        <span class="keyword">return</span> np.array(seq), np.array(next_char)       <span class="comment"># [batch_size, seq_length], [num_batch]</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RNN</span><span class="params">(tf.keras.Model)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_chars, batch_size, seq_length)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.num_chars = num_chars</span><br><span class="line">        self.seq_length = seq_length</span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line">        self.cell = tf.keras.layers.LSTMCell(units=<span class="number">256</span>)</span><br><span class="line">        self.dense = tf.keras.layers.Dense(units=self.num_chars)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, inputs, from_logits=False)</span>:</span></span><br><span class="line">        inputs = tf.one_hot(inputs, depth=self.num_chars)       <span class="comment"># [batch_size, seq_length, num_chars]</span></span><br><span class="line">        state = self.cell.get_initial_state(batch_size=self.batch_size, dtype=tf.float32)</span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> range(self.seq_length):</span><br><span class="line">            output, state = self.cell(inputs[:, t, :], state)</span><br><span class="line">        logits = self.dense(output)</span><br><span class="line">        <span class="keyword">if</span> from_logits:</span><br><span class="line">            <span class="keyword">return</span> logits</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> tf.nn.softmax(logits)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, inputs, temperature=<span class="number">1.</span>)</span>:</span></span><br><span class="line">        batch_size, _ = tf.shape(inputs)</span><br><span class="line">        logits = self(inputs, from_logits=<span class="literal">True</span>)</span><br><span class="line">        prob = tf.nn.softmax(logits / temperature).numpy()</span><br><span class="line">        <span class="keyword">return</span> np.array([np.random.choice(self.num_chars, p=prob[i, :])</span><br><span class="line">                         <span class="keyword">for</span> i <span class="keyword">in</span> range(batch_size.numpy())])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trainRnn</span><span class="params">()</span>:</span></span><br><span class="line">    num_batches = <span class="number">1000</span></span><br><span class="line">    seq_length = <span class="number">40</span></span><br><span class="line">    batch_size = <span class="number">50</span></span><br><span class="line">    learning_rate = <span class="number">1e-3</span></span><br><span class="line">    data_loader = TextLoader()</span><br><span class="line">    model = RNN(num_chars=len(data_loader.chars), batch_size=batch_size, seq_length=seq_length)</span><br><span class="line">    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)</span><br><span class="line">    <span class="keyword">for</span> batch_index <span class="keyword">in</span> range(num_batches):</span><br><span class="line">        X, y = data_loader.get_batch(seq_length, batch_size)</span><br><span class="line">        <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">            y_pred = model(X)</span><br><span class="line">            loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_pred)</span><br><span class="line">            loss = tf.reduce_mean(loss)</span><br><span class="line">            print(<span class="string">"batch %d: loss %f"</span> % (batch_index, loss.numpy()))</span><br><span class="line">        grads = tape.gradient(loss, model.variables)</span><br><span class="line">        optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))</span><br><span class="line"></span><br><span class="line">    <span class="comment">#雪球式预测下个char</span></span><br><span class="line">    X_, _ = data_loader.get_batch(seq_length, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> diversity <span class="keyword">in</span> [<span class="number">0.2</span>, <span class="number">0.5</span>, <span class="number">1.0</span>, <span class="number">1.2</span>]:</span><br><span class="line">        X = X_</span><br><span class="line">        print(<span class="string">"diversity %f:"</span> % diversity)</span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">400</span>):</span><br><span class="line">            y_pred = model.predict(X, diversity)</span><br><span class="line">            print(data_loader.indices_char[y_pred[<span class="number">0</span>]], end=<span class="string">''</span>, flush=<span class="literal">True</span>)</span><br><span class="line">            X = np.concatenate([X[:, <span class="number">1</span>:], np.expand_dims(y_pred, axis=<span class="number">1</span>)], axis=<span class="number">-1</span>)</span><br><span class="line">        print(<span class="string">"\n"</span>)</span><br><span class="line">trainRnn()</span><br></pre></td></tr></table></figure></li><li><p>利用keras的高级api建立模型 sequential通过向 tf.keras.models.Sequential() 提供一个层的列表，就能快速地建立一个 tf.keras.Model 模型并返回：</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    tf.keras.layers.Flatten(),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">100</span>,activation=tf.nn.sigmoid),</span><br><span class="line">    <span class="comment"># tf.keras.layers.Dense(64,activation=tf.nn.relu),</span></span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>),</span><br><span class="line">    tf.keras.layers.Softmax()</span><br><span class="line">    ])</span><br><span class="line"><span class="comment">#Keras 提供了 Functional API，帮助我们建立更为复杂的模型，例如多输入 / 输出或存在参数共享的模型</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">FunctionalCreate</span><span class="params">()</span>:</span></span><br><span class="line">    inputs = tf.keras.Input(shape=(<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>))</span><br><span class="line">    x = tf.keras.layers.Flatten()(inputs)</span><br><span class="line">    x = tf.keras.layers.Dense(units=<span class="number">100</span>, activation=tf.nn.relu)(x)</span><br><span class="line">    x = tf.keras.layers.Dense(units=<span class="number">10</span>)(x)</span><br><span class="line">    outputs = tf.keras.layers.Softmax()(x)</span><br><span class="line">    model = tf.keras.Model(inputs=inputs, outputs=outputs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"><span class="comment"># trainMLP(MLP())</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">apitrain</span><span class="params">()</span>:</span></span><br><span class="line">    model = MLP()</span><br><span class="line">    <span class="comment">#使用kerasmodel的三个方法训练和评估</span></span><br><span class="line">    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=<span class="number">0.001</span>)</span><br><span class="line">        ,loss=tf.keras.losses.sparse_categorical_crossentropy</span><br><span class="line">        ,metrics=[tf.keras.metrics.sparse_categorical_accuracy])</span><br><span class="line">    <span class="comment">#complle接受 优化器，损失函数，评估指标都从对应的类里选</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    model.fit(MNISTLoader().train_data,MNISTLoader().train_label,epochs=<span class="number">3</span>,batch_size=<span class="number">100</span>)</span><br><span class="line">    <span class="comment">#返回列表包含最终loss和accuracy 在这里测试之前的模型准确率都上升了</span></span><br><span class="line">    print(<span class="string">'\n'</span>,model.evaluate(MNISTLoader().test_data,MNISTLoader().test_label))</span><br><span class="line">apitrain()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;  学习tensorflow的经验和总结&lt;/p&gt;
    
    </summary>
    
    
      <category term="Tensorflow" scheme="https://kivid.github.io/categories/Tensorflow/"/>
    
    
      <category term="Tensorflow" scheme="https://kivid.github.io/tags/Tensorflow/"/>
    
      <category term="笔记" scheme="https://kivid.github.io/tags/%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>给文章加密</title>
    <link href="https://kivid.github.io/2020/05/07/%E7%BB%99%E6%96%87%E7%AB%A0%E5%8A%A0%E5%AF%86/"/>
    <id>https://kivid.github.io/2020/05/07/%E7%BB%99%E6%96%87%E7%AB%A0%E5%8A%A0%E5%AF%86/</id>
    <published>2020-05-07T09:49:54.000Z</published>
    <updated>2020-05-07T10:03:02.438Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\blog\assets\js\Meting.min.js"></script><p>Next主题没有发现内置加密，试试脚本加密</p><a id="more"></a><h4 id="实现方法"><a href="#实现方法" class="headerlink" title="实现方法"></a>实现方法</h4><ul><li>在主题文件下layout/_partials/head.swig插入如下代码<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="actionscript">    (<span class="function"><span class="keyword">function</span><span class="params">()</span></span>&#123;</span></span><br><span class="line"><span class="actionscript">        <span class="keyword">if</span>(<span class="string">'&#123;&#123; page.password &#125;&#125;'</span>)&#123;</span></span><br><span class="line"><span class="actionscript">            <span class="keyword">if</span> (prompt(<span class="string">'请输入文章密码'</span>) !== <span class="string">'&#123;&#123; page.password &#125;&#125;'</span>)&#123;</span></span><br><span class="line"><span class="actionscript">                alert(<span class="string">'密码错误！'</span>);</span></span><br><span class="line">                history.back();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;)();</span><br><span class="line"><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li>然后写文章加个password字段类似<br>titile: your title<br>password: your password</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Next主题没有发现内置加密，试试脚本加密&lt;/p&gt;
    
    </summary>
    
    
      <category term="blog" scheme="https://kivid.github.io/categories/blog/"/>
    
    
      <category term="blog" scheme="https://kivid.github.io/tags/blog/"/>
    
  </entry>
  
  <entry>
    <title>Hello_Hexo</title>
    <link href="https://kivid.github.io/2020/05/05/Hello-Hexo/"/>
    <id>https://kivid.github.io/2020/05/05/Hello-Hexo/</id>
    <published>2020-05-05T14:44:59.000Z</published>
    <updated>2020-05-07T11:17:01.312Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\blog\assets\js\Meting.min.js"></script><p>本篇主要介绍如何用Hexo搭建Github Pages，并且对比了同类静态博客框架，记录了部署方面的易错认知，提出了一些常用插件及美化博客的思路。PS：本文非小白教程类</p><a id="more"></a><h2 id="Hexo-GitHub-Pages"><a href="#Hexo-GitHub-Pages" class="headerlink" title="Hexo+GitHub Pages"></a>Hexo+GitHub Pages</h2><p>第一次使用GitHubpages发布博客，之前是wordpress的动态博客，但由于博客性质适合静态网页，于是跳到两年前埋下伏笔处Githubpages。既不用续域名做备案，也不用租用服务器（虽然牛客网那白嫖了一年华为云的）。</p><h4 id="jekyll-or-hexo"><a href="#jekyll-or-hexo" class="headerlink" title="jekyll or hexo"></a>jekyll or hexo</h4><p>​    目前两大静态博客框架：<a href="jekyllcn.com">Jekyll</a>和<a href="heox.io">hexo</a>。</p><ul><li>前者本身是被GitHub采用渲染的，而后者是先生成静态文件再上传，由此分离开来。</li><li>另一个大区别是依赖，前者需要本地安装ruby等而后者需要nodejs，他们的环境配置都有相应文档，另外hexo中文文档对我这种低水平英语很贴心</li></ul><h4 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h4><ul><li>经过探索参考博客，纠正了自己几个错误认知：<ol><li>hexo初始化后文件夹位置自由，所以如果把他放到一个repo就能通过clone来多端写文（我是放在user-page的repo），这样既能管理blog也能做其他静态web项目（如HX）。</li><li>我之前有个错误认知是只能访问user-page（也就是username.github.io），其实每个repo都能设置page（如username.github.io/blog，它是blog库的一个分支），它需要的是一个分支。而userpage只能是master分支。。</li><li>需要deploy时需npm下载git的包，站点配置文件的deploy项改为对应的repo和对应分支（国内gitee同样）。</li></ol></li><li>本站使用的Next主题。先据hexo文档配置好hexo环境，再下载主题到配置文件theme中，通过git clone <em>repo_url</em>  theme/next 一步完成也可下载压缩包解压到theme目录下。修改站点配置文件的theme字段即可。需要查看next的文档来配置，继而有下面的特效美化 </li></ul><h2 id="博客美化（待续）"><a href="#博客美化（待续）" class="headerlink" title="博客美化（待续）"></a>博客美化（待续）</h2><blockquote><p>下面在next配置文件有接口不用多写代码，看其文档使用方法再进主题配置文件修改，下面主要针对其他类</p></blockquote><h4 id="评论系统"><a href="#评论系统" class="headerlink" title="评论系统"></a>评论系统</h4><ul><li>此外有韩国<a href="livere.com">来必力</a>。在next主题中使用参见<a href="http://theme-next.iissnan.com/third-party-services.html" target="_blank" rel="noopener">文档</a>第三方服务来配置。</li><li>基于github-issue的<a href="https://imsun.net/posts/gitment-introduction/" target="_blank" rel="noopener">gitment</a></li><li>另找到个valine有使用<a href="https://valine.js.org" target="_blank" rel="noopener">文档</a> 注册用的leancloud可以再创建个app给下面阅读量用<ul><li>在2020.4.22的更新中：修复使用了低版本的<code>av-min.js</code>造成的初始化错误，这也是当前next主题还未修改的。只需要将_src=”//cdn1.lncld.net/static/js/3.0.4/av-min.js引入的这个leancloud操作库注释，否则会出现AV对象没有初始化的报错</li></ul></li><li>PS：摘要使用<!--more-->分割；阅读全文修改主题配置auto_excerpt字段</li></ul><h4 id="恶搞标题"><a href="#恶搞标题" class="headerlink" title="恶搞标题"></a>恶搞标题</h4><ul><li><p>点击<a href="diygod.me">效果</a></p></li><li><p>在主题文件下找到head文件里加入</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> OriginTitle = <span class="built_in">document</span>.title;</span><br><span class="line"><span class="keyword">var</span> titleTime;</span><br><span class="line"><span class="built_in">document</span>.addEventListener(<span class="string">'visibilitychange'</span>, <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">document</span>.hidden) &#123;</span><br><span class="line">        $(<span class="string">'[rel="icon"]'</span>).attr(<span class="string">'href'</span>, <span class="string">"/img/trhx2.png"</span>);</span><br><span class="line">        <span class="built_in">document</span>.title = <span class="string">'ヽ(●-`Д´-)ノ人呢！'</span>;</span><br><span class="line">        clearTimeout(titleTime);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        $(<span class="string">'[rel="icon"]'</span>).attr(<span class="string">'href'</span>, <span class="string">"/img/trhx2.png"</span>);</span><br><span class="line">        <span class="built_in">document</span>.title = <span class="string">'ヾ(Ő∀Ő3)ノ回来了！'</span> + OriginTitle;</span><br><span class="line">        titleTime = setTimeout(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">            <span class="built_in">document</span>.title = OriginTitle;</span><br><span class="line">        &#125;, <span class="number">2000</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></li></ul><h4 id="看板娘"><a href="#看板娘" class="headerlink" title="看板娘"></a>看板娘</h4><ul><li><a href="https://www.cnblogs.com/ButterflyEffect/p/10839613.html" target="_blank" rel="noopener">live2d</a></li></ul><h4 id="点击滑动特效"><a href="#点击滑动特效" class="headerlink" title="点击滑动特效"></a>点击滑动特效</h4><ul><li><p>点击🎈爆炸:放在主题文件下_layout文件中</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 点击出现彩色气球爆炸效果 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">canvas</span> <span class="attr">class</span>=<span class="string">"fireworks"</span> <span class="attr">style</span>=<span class="string">"position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;"</span> &gt;</span><span class="tag">&lt;/<span class="name">canvas</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span> <span class="attr">src</span>=<span class="string">"//cdn.bootcss.com/animejs/2.2.0/anime.min.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"https://cdn.jsdelivr.net/gh/wallleap/cdn/js/clickBom.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ul><ul><li><p>光标 点击烟花效果<a href="https://www.cnblogs.com/axqa/p/11537599.html" target="_blank" rel="noopener">这里</a></p></li><li><p>鼠标滑过特效 星星残影：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"https://cdn.jsdelivr.net/gh/wallleap/cdn/js/xuehua.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ul><h4 id="网站运行时"><a href="#网站运行时" class="headerlink" title="网站运行时"></a>网站运行时</h4><ul><li><p>在主题footer加入：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">id</span>=<span class="string">"timeDate"</span>&gt;</span>载入天数...<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">id</span>=<span class="string">"times"</span>&gt;</span>载入时分秒...<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="javascript">  <span class="keyword">var</span> now = <span class="keyword">new</span> <span class="built_in">Date</span>(); </span></span><br><span class="line"><span class="actionscript">  <span class="function"><span class="keyword">function</span> <span class="title">createtime</span><span class="params">()</span> </span>&#123; </span></span><br><span class="line"><span class="javascript">    <span class="keyword">var</span> grt= <span class="keyword">new</span> <span class="built_in">Date</span>(<span class="string">"03/08/2020 16:44:00"</span>);<span class="comment">//此处修改你的建站时间或者网站上线时间 </span></span></span><br><span class="line">    now.setTime(now.getTime()+250); </span><br><span class="line"><span class="javascript">    days = (now - grt ) / <span class="number">1000</span> / <span class="number">60</span> / <span class="number">60</span> / <span class="number">24</span>; dnum = <span class="built_in">Math</span>.floor(days); </span></span><br><span class="line"><span class="javascript">    hours = (now - grt ) / <span class="number">1000</span> / <span class="number">60</span> / <span class="number">60</span> - (<span class="number">24</span> * dnum); hnum = <span class="built_in">Math</span>.floor(hours); </span></span><br><span class="line"><span class="javascript">    <span class="keyword">if</span>(<span class="built_in">String</span>(hnum).length ==<span class="number">1</span> )&#123;hnum = <span class="string">"0"</span> + hnum;&#125; minutes = (now - grt ) / <span class="number">1000</span> /<span class="number">60</span> - (<span class="number">24</span> * <span class="number">60</span> * dnum) - (<span class="number">60</span> * hnum); </span></span><br><span class="line"><span class="javascript">    mnum = <span class="built_in">Math</span>.floor(minutes); <span class="keyword">if</span>(<span class="built_in">String</span>(mnum).length ==<span class="number">1</span> )&#123;mnum = <span class="string">"0"</span> + mnum;&#125; </span></span><br><span class="line">    seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); </span><br><span class="line"><span class="javascript">    snum = <span class="built_in">Math</span>.round(seconds); <span class="keyword">if</span>(<span class="built_in">String</span>(snum).length ==<span class="number">1</span> )&#123;snum = <span class="string">"0"</span> + snum;&#125; </span></span><br><span class="line"><span class="javascript">    <span class="built_in">document</span>.getElementById(<span class="string">"timeDate"</span>).innerHTML = <span class="string">"本站已安全运行 "</span>+dnum+<span class="string">" 天 "</span>; </span></span><br><span class="line"><span class="javascript">    <span class="built_in">document</span>.getElementById(<span class="string">"times"</span>).innerHTML = hnum + <span class="string">" 小时 "</span> + mnum + <span class="string">" 分 "</span> + snum + <span class="string">" 秒"</span>; </span></span><br><span class="line">  &#125; </span><br><span class="line"><span class="actionscript">  setInterval(<span class="string">"createtime()"</span>,<span class="number">250</span>);</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ul><h4 id="背景显示飘动的彩带"><a href="#背景显示飘动的彩带" class="headerlink" title="背景显示飘动的彩带"></a>背景显示飘动的彩带</h4><ul><li><p>同上layout：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"https://cdn.jsdelivr.net/gh/wallleap/cdn/js/piao.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>背景显示分子状线条</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"https://cdn.jsdelivr.net/gh/wallleap/cdn/js/canvas-nest.min.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ul><h4 id="樱花飘落或雪花飘落"><a href="#樱花飘落或雪花飘落" class="headerlink" title="樱花飘落或雪花飘落"></a>樱花飘落或雪花飘落</h4><ul><li>樱花src：_<a href="https://cdn.jsdelivr.net/gh/wallleap/cdn/js/sakura.js_同上位置" target="_blank" rel="noopener">https://cdn.jsdelivr.net/gh/wallleap/cdn/js/sakura.js_同上位置</a></li><li>雪花src: _<a href="https://cdn.jsdelivr.net/gh/wallleap/cdn/js/xuehuapiaoluo.js_或者_https://cdn.jsdelivr.net/gh/wallleap/cdn/js/snow.js_选择一个" target="_blank" rel="noopener">https://cdn.jsdelivr.net/gh/wallleap/cdn/js/xuehuapiaoluo.js_或者_https://cdn.jsdelivr.net/gh/wallleap/cdn/js/snow.js_选择一个</a></li></ul><h4 id="禁用按键"><a href="#禁用按键" class="headerlink" title="禁用按键"></a>禁用按键</h4><ul><li><p>禁用了右键F12等</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"https://cdn.jsdelivr.net/gh/wallleap/cdn/js/noSomeKey.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ul><h4 id="wordcout"><a href="#wordcout" class="headerlink" title="wordcout"></a>wordcout</h4><ul><li><p>在主题有字段post_wordcout：需要先npm下载hexo-wordcout才能用</p></li><li><p>另外默认没有单位，修改themes\next\layout_macro\post.swig：例如</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">title</span>=<span class="string">"&#123;&#123; __('post.min2read') &#125;&#125;"</span>&gt;</span></span><br><span class="line">   &#123;&#123; min2read(post.content) &#125;&#125; 分钟</span><br><span class="line"> <span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ul><h4 id="更多特效"><a href="#更多特效" class="headerlink" title="更多特效"></a>更多特效</h4><ul><li><a href="https://blog.csdn.net/u011475210/article/details/79023429#comments" target="_blank" rel="noopener">播放器头像旋转等</a>、<a href="https://blog.csdn.net/weixin_43738731/article/details/85843474" target="_blank" rel="noopener">next深度定制</a>、添加文章阅读量统计功能（next文档第三方服务部分：记得手动加Counter类）、数据统计与分析</li></ul><h4 id="解决时延问题"><a href="#解决时延问题" class="headerlink" title="解决时延问题"></a>解决时延问题</h4><p><img src="data:image/png;base64,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" data-original="https://kivid.github.io/blog/image/%E8%A7%A3%E5%86%B3%E6%97%B6%E5%BB%B6.png" alt="需要根据public结构"></p><ul><li>发布后发现加载过慢于是看看是什么原因。第一个是font即谷歌字体的镜像网站无法访问，本来查了些镜像站发现不会用，而原本默认的居然能访问于是在主题配置文件中更改font字段下的host。</li><li>第二个是disq第三方评论网站被墙，只需将其字段设false。</li><li>还有个是head的背景图片url失效去主题博主网站<a href="https://notes.doublemine.me/images/header-background.jpg" target="_blank" rel="noopener">下载了</a>（不知道为什么能Get到可能是本地的）。但本地应用由于hexo生成public文件夹发布会找不到于是使用其url（在head-style文件）</li><li>Aplayer是js没有找到，查看博客的repo文件。</li><li>网易云外链在博客只能点击几首歌，在这里发现是外链问题。依次对单曲产生外链发现是版权问题。</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li><p>搭建hexo博客已经是一搜一大片。如果是第一次做先弄清楚前端相关知识，再从hexo理解和文档入手。配置好环境条件：能生成一个本地能访问的前端。再者就是配置基础项可见文档，如何发布文档和上面已经说明。只是发文到此可止。</p></li><li><p>美化博客就像DIY（像我们这种后端）简直就是东拼西凑。第一步是换个生态好的，稳定维护的主题，我用的是魔改的Next。文档之全面让我们与代码分离开来。下面就是本博客的主要得分。</p></li></ul><ol><li><p>先是博客插件。第一个就是给静态博客添加评论系统，参考文档发现next加入了诸多第三方评论系统。例如valine、gitment、来必力等。使用方法都很简单，注册拿到appid和appkey 插入到主题配置文件的相应字段。</p></li><li><p>还有就是文章字数显示浏览次数用的wordcount和leancloud都在文档有接口</p></li><li><p>另外就是参考diygod博客的小交互，例如点击烟花，吸底apalyer，背景点击变化</p></li><li><p>还有些tips：摘要分割（需改主题配置），博客边界阴影，看板娘，评论区加入每日一词和正则检验，文章加密，side：头像转动，划入显示链接。</p><p>PS：点击菜单链接中有%20应该是空格字符转义，删除||前面空格可用。菜单中除了about和404需要写其他都能生成。</p></li><li><p>现在还有个点是valine admin没有部署（评论邮件通知），因为leancloud没配置好，可能要另外域名来绑定才行.</p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本篇主要介绍如何用Hexo搭建Github Pages，并且对比了同类静态博客框架，记录了部署方面的易错认知，提出了一些常用插件及美化博客的思路。PS：本文非小白教程类&lt;/p&gt;
    
    </summary>
    
    
      <category term="blog" scheme="https://kivid.github.io/categories/blog/"/>
    
    
      <category term="Githubpages" scheme="https://kivid.github.io/tags/Githubpages/"/>
    
      <category term="Hexo" scheme="https://kivid.github.io/tags/Hexo/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://kivid.github.io/2020/05/05/hello-world/"/>
    <id>https://kivid.github.io/2020/05/05/hello-world/</id>
    <published>2020-05-05T10:24:03.199Z</published>
    <updated>2020-05-07T10:03:18.722Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\blog\assets\js\Meting.min.js"></script><p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\blog\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\blog\assets\js\APlayer.m
      
    
    </summary>
    
    
    
  </entry>
  
</feed>
